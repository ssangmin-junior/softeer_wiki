1. Keep:
    - Web Scraping: 필요한 데이터를 자동으로 수집할 수 있는 기술을 익힘.
    - Pandas DataFrame: 데이터 처리 및 분석에 효율적인 도구 사용.
    - ETL Process: 데이터를 체계적으로 처리하는 방법을 이해함.
    - Database & SQL: 데이터베이스에 대한 기초 지식을 습득함.
2. Problem:
    - 웹 스크래핑 중 발생한 예기치 않은 데이터 구조 변경.
    - SQL 쿼리 작성 시 발생한 문법 오류.
3. Problem 해결책:
    - 웹 스크래핑 문제 해결책: 데이터 구조 변경을 대비해 스크래핑 코드의 유연성을 높이고, 예외 처리를 강화하기.
    - SQL 쿼리 문제 해결책: SQL 쿼리의 문법을 철저히 검토하고, 작은 쿼리로 나눠서 테스트하기.
4. Try:
    - 스크래핑 도구의 확장: selenium, Scrapy 등 다양한 스크래핑 도구를 시도해보기.
    
    - 자동화 스크립트 작성: 반복되는 ETL 작업을 자동화하기 위한 스크립트를 작성해보기.

### ETL로 구분하여 이용하는 이유

ETL(Process)로 데이터를 처리하는 이유는 데이터 수집, 변환, 로드의 체계적 관리가 가능하기 때문임.

- **Extract**: 다양한 소스에서 데이터를 자동으로 수집하여 데이터 수집의 효율성을 높임.
- **Transform**: 수집된 데이터를 분석에 적합한 형태로 변환하여 데이터 일관성과 품질을 유지함.
- **Load**: 변환된 데이터를 데이터베이스에 로드하여 데이터의 중앙 집중화 및 관리 용이성을 제공함.

이렇게 ETL 과정을 통해 데이터를 효율적으로 관리하고, 분석 및 활용할 수 있음.
