# 0807

## Keep

- **데이터 파이프라인 요소 학습**
    - 데이터 파이프라인의 각 요소에 대해 공부함.
    - Kafka, Kinesis, Airflow, EMR, S3, Data Warehouse, RDS, QuickSight, Grafana 등의 역할과 사용 예를 이해함.
- **데이터 파이프라인 구상**
    - Kafka 또는 Kinesis를 사용하여 SNS 게시글을 수집하고, Airflow를 통해 ETL 작업을 스케줄링하며, EMR을 통해 대규모 데이터를 처리하는 파이프라인을 구상함.
    - 데이터를 S3에 저장하고, Redshift 또는 RDS에 분석용 데이터를 저장하며, QuickSight 또는 Grafana를 사용하여 데이터를 시각화하고 대시보드를 생성하는 방법을 이해함.

## Problem

- **데이터 처리 방법 결정의 어려움**
    - 실시간 데이터를 처리하기 위해 Kafka를 사용하는 것은 명확하지만, 과거에 적재된 데이터를 EMR을 통해 처리할지, S3에서 RDS로 바로 넣을지 고민 중임.
    - 대규모 데이터와 소규모 데이터 처리 방법을 각각 어떻게 최적화할지에 대한 고민이 있음.

## Try

- **데이터 처리 방법 결정**
    - **대규모 데이터 처리**: 과거 데이터를 대규모로 처리하고 복잡한 분석 또는 머신 러닝 작업이 필요한 경우 EMR을 사용하는 것이 좋음.
    - **소규모 데이터 처리**: 데이터 규모가 작고 간단한 ETL 작업이나 데이터베이스 로드 작업이 필요한 경우 S3와 RDS를 사용하는 것이 더 효율적임.
- **구체적인 데이터 파이프라인 예시**
    - **데이터 수집**: Kafka 또는 Kinesis를 사용하여 실시간으로 SNS 게시글 수집.
    - **데이터 처리**: Airflow를 사용하여 ETL 작업 스케줄링, EMR을 사용하여 대규모 데이터 처리.
    - **데이터 저장**: 처리된 데이터를 S3에 저장, 분석용 데이터는 Redshift 또는 RDS에 저장.
    - **데이터 분석 및 시각화**: QuickSight 또는 Grafana를 사용하여 데이터를 시각화하고 대시보드 생성.
- **LLM (LLaMA) 튜닝**
    - 게시글을 결함 카탈로그(약 20개)로 분류할 수 있는 LLM (LLaMA)를 튜닝 중임.
    - 모델 튜닝을 통해 결함 카탈로그로 정확하게 분류하는 성능을 향상시키기.

데이터 파이프라인의 각 요소에 대해 공부함.

### 

실시간 성 데이터를 이용하기 위해 kafka를 쓰는데, 과거에 적재된 데이터를 EMR을 통해 작업할지, 그냥 s3로 rds에 넣을 지 고민중임.

- **대규모 데이터 처리**: 과거 데이터를 대규모로 처리해야 하고 복잡한 분석 또는 머신 러닝 작업이 필요한 경우 EMR을 사용하는 것이 좋습니다.
- **소규모 데이터 처리**: 데이터 규모가 작고 간단한 ETL 작업이나 데이터베이스 로드 작업이 필요한 경우 S3와 RDS를 사용하는 것이 더 효율적입니다.
    
    
    게시글을 결함 카탈로그(약20개)로 분류할 수 있는 LLM (라마)를 튜닝중
